{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_dir = Path('store-sales-time-series-forecasting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_events = pd.read_csv(\n",
    "    comp_dir / \"holidays_events.csv\",\n",
    "    dtype={\n",
    "        'type': 'category',\n",
    "        'locale': 'category',\n",
    "        'locale_name': 'category',\n",
    "        'description': 'category',\n",
    "        'transferred': 'bool',\n",
    "    },\n",
    "    parse_dates=['date']\n",
    ")\n",
    "holidays_events = holidays_events.set_index('date').to_period('D')\n",
    "\n",
    "store_sales = pd.read_csv(\n",
    "    comp_dir / 'train.csv',\n",
    "    usecols=['store_nbr', 'family', 'date', 'sales'],\n",
    "    dtype={\n",
    "        'store_nbr': 'category',\n",
    "        'family': 'category',\n",
    "        'sales': 'float32',\n",
    "    },\n",
    "    parse_dates=['date'],\n",
    ")\n",
    "store_sales['date'] = store_sales.date.dt.to_period('D')\n",
    "store_sales = store_sales.set_index(['store_nbr', 'family', 'date']).sort_index()\n",
    "average_sales = (\n",
    "    store_sales\n",
    "    .groupby('date').mean()\n",
    "    .squeeze()\n",
    "    .loc['2017']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = pd.read_csv(comp_dir / 'stores.csv', dtype={'store_nbr': 'category'})\n",
    "oil = pd.read_csv(comp_dir / 'oil.csv', parse_dates=['date'])\n",
    "oil['date'] = oil['date'].dt.to_period('D')\n",
    "transactions = pd.read_csv(comp_dir / 'transactions.csv', parse_dates=['date'])\n",
    "transactions['date'] = transactions['date'].dt.to_period(('D'))\n",
    "transactions['store_nbr'] = transactions['store_nbr'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(df):\n",
    "    df = df.reset_index().merge(stores, on='store_nbr', how='left')\n",
    "    df = df.merge(oil, on='date', how='left')\n",
    "    df = df.merge(holidays_events, on='date', how='left')\n",
    "    df = df.merge(transactions, on=['date', 'store_nbr'], how='left')\n",
    "    df = df.set_index(['store_nbr', 'family', 'date']).sort_index()\n",
    "    return df\n",
    "\n",
    "train = merge_data(store_sales)\n",
    "\n",
    "# Создание дополнительных признаков из даты\n",
    "def create_date_features(df):\n",
    "    df['year'] = df.index.get_level_values('date').year\n",
    "    df['month'] = df.index.get_level_values('date').month\n",
    "    df['day'] = df.index.get_level_values('date').day\n",
    "    df['dayofweek'] = df.index.get_level_values('date').dayofweek\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = train.select_dtypes(include=['object']).columns\n",
    "numeric_columns = train.select_dtypes(include=['number']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', lgb)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3r/3vnn_h3j4kv3w8dbk43mbfsc0000gn/T/ipykernel_31217/1409349651.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f'{col}_lag_{lag}'] = df[col].groupby(level=['store_nbr', 'family']).shift(lag)\n",
      "/var/folders/3r/3vnn_h3j4kv3w8dbk43mbfsc0000gn/T/ipykernel_31217/1409349651.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f'{col}_lag_{lag}'] = df[col].groupby(level=['store_nbr', 'family']).shift(lag)\n",
      "/var/folders/3r/3vnn_h3j4kv3w8dbk43mbfsc0000gn/T/ipykernel_31217/1409349651.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f'{col}_lag_{lag}'] = df[col].groupby(level=['store_nbr', 'family']).shift(lag)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['store_nbr', 'family', 'onpromotion'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Определение признаков и целевой переменной\u001b[39;00m\n\u001b[1;32m     23\u001b[0m features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_nbr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfamily\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monpromotion\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransactions\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdcoilwtico\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdayofweek\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m     24\u001b[0m            [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msales_lag_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m lags]\n\u001b[0;32m---> 25\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     26\u001b[0m y \u001b[38;5;241m=\u001b[39m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msales\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Разделение данных на обучающую и тестовую выборки\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['store_nbr', 'family', 'onpromotion'] not in index\""
     ]
    }
   ],
   "source": [
    "# Создание дополнительных признаков из даты\n",
    "def create_date_features(df):\n",
    "    df['year'] = df.index.get_level_values('date').year\n",
    "    df['month'] = df.index.get_level_values('date').month\n",
    "    df['day'] = df.index.get_level_values('date').day\n",
    "    df['dayofweek'] = df.index.get_level_values('date').dayofweek\n",
    "    return df\n",
    "\n",
    "train = create_date_features(train)\n",
    "\n",
    "# Создание лагов\n",
    "def create_lag_features(df, lags, col):\n",
    "    for lag in lags:\n",
    "        df[f'{col}_lag_{lag}'] = df[col].groupby(level=['store_nbr', 'family']).shift(lag)\n",
    "\n",
    "lags = [1, 7, 30]\n",
    "create_lag_features(train, lags, 'sales')\n",
    "\n",
    "# Удаление строк с пропущенными значениями (появившимися из-за лагов)\n",
    "train.dropna(inplace=True)\n",
    "\n",
    "# Определение признаков и целевой переменной\n",
    "features = ['store_nbr', 'family', 'onpromotion', 'transactions', 'dcoilwtico', 'year', 'month', 'day', 'dayofweek'] + \\\n",
    "           [f'sales_lag_{lag}' for lag in lags]\n",
    "X = train[features]\n",
    "y = train['sales']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
